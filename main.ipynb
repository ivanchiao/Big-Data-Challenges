{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2021 Wechat Big Data Challenges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import time\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainTensorData(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, inputs_feat, inputs_label, use_label):    \n",
    "        self.inputs_feat = inputs_feat\n",
    "        self.inputs_label = inputs_label\n",
    "        self.use_label = use_label\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        userid = self.inputs_feat['userid'][index] \n",
    "        feedid = self.inputs_feat['feedid'][index]\n",
    "        device = self.inputs_feat['device'][index]\n",
    "        \n",
    "        # feed\n",
    "        authorid = self.inputs_feat['authorid'][feedid]\n",
    "        bgm_song_id = self.inputs_feat['bgm_song_id'][feedid]\n",
    "        bgm_singer_id = self.inputs_feat['bgm_singer_id'][feedid]\n",
    "        feed_embeddings = self.inputs_feat['feed_embeddings'][feedid]\n",
    "        tags = self.inputs_feat['tags'][feedid]\n",
    "        keywords = self.inputs_feat['keywords'][feedid]\n",
    "        videoplayseconds_discrete = self.inputs_feat['videoplayseconds_discrete'][feedid]\n",
    "        \n",
    "        # user\n",
    "        # feed_history = self.inputs_feat['feed_history'][userid]\n",
    "        label = self.inputs_label[self.use_label][index]\n",
    "        \n",
    "        sparseX = {\n",
    "            'userid' : userid,\n",
    "            'feedid' : feedid,\n",
    "            'authorid': authorid,\n",
    "            'bgm_song_id': bgm_song_id,\n",
    "            'bgm_singer_id': bgm_singer_id,\n",
    "            'device': device,\n",
    "            'videoplayseconds_discrete' : videoplayseconds_discrete,\n",
    "        }\n",
    "        \n",
    "        varlenX = {\n",
    "            'tags': tags,\n",
    "            'keywords': keywords,\n",
    "        }\n",
    "        \n",
    "        denseX = {\n",
    "            'feed_embeddings': feed_embeddings,\n",
    "            # 'feed_history': feed_history,\n",
    "        }\n",
    "        \n",
    "        return sparseX, varlenX, denseX, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.inputs_feat['userid'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestTensorData(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, inputs_feat):    \n",
    "        self.inputs_feat = inputs_feat\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        userid = self.inputs_feat['userid'][index] \n",
    "        feedid = self.inputs_feat['feedid'][index]\n",
    "        device = self.inputs_feat['device'][index]\n",
    "        \n",
    "        # feed\n",
    "        authorid = self.inputs_feat['authorid'][feedid]\n",
    "        bgm_song_id = self.inputs_feat['bgm_song_id'][feedid]\n",
    "        bgm_singer_id = self.inputs_feat['bgm_singer_id'][feedid]\n",
    "        feed_embeddings = self.inputs_feat['feed_embeddings'][feedid]\n",
    "        tags = self.inputs_feat['tags'][feedid]\n",
    "        keywords = self.inputs_feat['keywords'][feedid]\n",
    "        videoplayseconds_discrete = self.inputs_feat['videoplayseconds_discrete'][feedid]\n",
    "        \n",
    "        # user\n",
    "        # feed_history = self.inputs_feat['feed_history'][userid]\n",
    "        \n",
    "        sparseX = {\n",
    "            'userid' : userid,\n",
    "            'feedid' : feedid,\n",
    "            'authorid': authorid,\n",
    "            'bgm_song_id': bgm_song_id,\n",
    "            'bgm_singer_id': bgm_singer_id,\n",
    "            'device': device,\n",
    "            'videoplayseconds_discrete' : videoplayseconds_discrete,\n",
    "        }\n",
    "        \n",
    "        varlenX = {\n",
    "            'tags': tags,\n",
    "            'keywords': keywords,\n",
    "        }\n",
    "        \n",
    "        denseX = {\n",
    "            'feed_embeddings': feed_embeddings,\n",
    "            # 'feed_history': feed_history,\n",
    "        }\n",
    "        \n",
    "        return sparseX, varlenX, denseX\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.inputs_feat['userid'].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed侧特征以 0 作为 mask value\n",
    "def padding(origin):\n",
    "    if len(origin.shape) == 1:\n",
    "        return np.insert(origin, 0, 0, axis=0)\n",
    "\n",
    "    elif len(origin.shape) == 2:\n",
    "        pad = np.zeros(shape=(1, origin.shape[1]), dtype=origin.dtype)\n",
    "        return np.concatenate([pad, origin], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# videoplayseconds 离散化\n",
    "def videoplayseconds_discrete_process(df):\n",
    "    video_src = df['videoplayseconds'].unique()\n",
    "    video_des = {'des': np.arange(1, video_src.shape[0] + 1)}\n",
    "    video_map = pd.DataFrame(index=video_src, data=video_des)\n",
    "    videoplayseconds_discrete = video_map.loc[(df['videoplayseconds']).tolist()].values.squeeze()\n",
    "    videoplayseconds_discrete_voc = videoplayseconds_discrete.max()\n",
    "\n",
    "    return videoplayseconds_discrete, videoplayseconds_discrete_voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# videoplayseconds log+归一化\n",
    "def process_videoplayseconds(df):\n",
    "    videoplay = np.log(1 + df['videoplayseconds'])\n",
    "    videoplay = (videoplay - videoplay.min()) / (videoplay.max() - videoplay.min())\n",
    "\n",
    "    return videoplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_varlensparse(df, col_name):\n",
    "    df[col_name].fillna('-1', inplace=True)\n",
    "    feats = [list(map(eval, d.strip(' ').split(';'))) for d in df[col_name]]\n",
    "\n",
    "    # 全体向右移动 1个单位\n",
    "    for i in range(len(feats)):\n",
    "        for j in range(len(feats[i])):\n",
    "            feats[i][j] += 1\n",
    "\n",
    "    # 统计出现的最大id\n",
    "    feats_max_id = 0\n",
    "    for feat in feats:\n",
    "        for f in feat:\n",
    "            feats_max_id = max(f, feats_max_id)\n",
    "    \n",
    "    # 统计出现的最大长度\n",
    "    feats_max_len = 0\n",
    "    for feat in feats:\n",
    "        feats_max_len = max(len(feat), feats_max_len)\n",
    "\n",
    "    # 按最大长度填充 0\n",
    "    for i in range(len(feats)):\n",
    "        feats[i] = feats[i] + [0] * (feats_max_len - len(feats[i]))\n",
    "\n",
    "    feats = np.array(feats, dtype=np.int32)\n",
    "    feats = padding(feats)\n",
    "\n",
    "    return feats, feats_max_len, feats_max_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Split\n",
    "def split_data_to_train_validation(df):\n",
    "    train_df = df[df['date_'] < 14].reset_index(drop=True)\n",
    "    valid_df = df[df['date_'] == 14].reset_index(drop=True)\n",
    "\n",
    "    return train_df, valid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, SparseFeatInfoList, VarLenSparseFeatInfoList, init_std=0.00001, device='cpu'):\n",
    "\n",
    "        super(EmbeddingLayer, self).__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.init_std = init_std\n",
    "        self.emb_dict = self.create_embedding_matrix(SparseFeatInfoList, VarLenSparseFeatInfoList)\n",
    "\n",
    "    def create_embedding_matrix(self, SparseFeatInfoList, VarLenSparseFeatInfoList):\n",
    "        sparse_emb_dict = {v.name: nn.Embedding(v.vocabulary_size, v.emb_dim) for v in SparseFeatInfoList}\n",
    "        varlen_emb_dict = {v.name: nn.Embedding(v.vocabulary_size, v.emb_dim) for v in VarLenSparseFeatInfoList}\n",
    "\n",
    "        sparse_emb_dict.update(varlen_emb_dict)\n",
    "        emb_dict = nn.ModuleDict(sparse_emb_dict)\n",
    "\n",
    "        for tensor in emb_dict.values():\n",
    "            nn.init.normal_(tensor.weight, mean=0, std=self.init_std)\n",
    "\n",
    "        return emb_dict.to(self.device)\n",
    "\n",
    "    def get_seq_len(self, varlenX):\n",
    "        return {u: torch.sum(v != 0, dim=1, keepdim=True) for u, v in varlenX.items()}\n",
    "\n",
    "    def load_pre_emb(self, VarLenSparseFeat_emb, pretrain_emb):\n",
    "\n",
    "        emb = nn.Embedding(VarLenSparseFeat_emb.vocabulary_size, VarLenSparseFeat_emb.emb_dim)\n",
    "        emb = emb.from_pretrained(pretrain_emb)\n",
    "        emb.weight.requires_grad = False  # note that\n",
    "        self.emb_dict.update(nn.ModuleDict({VarLenSparseFeat_emb.name: emb}))\n",
    "\n",
    "    def forward(self, sparseX, varlenX):\n",
    "\n",
    "        sparseX_emb = {u: self.emb_dict[u](v) for u, v in sparseX.items()}\n",
    "        varlenX_emb = {u: self.emb_dict[u](v) for u, v in varlenX.items()}\n",
    "\n",
    "        return sparseX_emb, varlenX_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequencePoolingLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, method='mean', device='cpu'):\n",
    "\n",
    "        super(SequencePoolingLayer, self).__init__()\n",
    "\n",
    "        self.method = method\n",
    "        self.device = device\n",
    "        self.eps = torch.FloatTensor([1e-8]).to(device)\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, varlen_list, seqlen_list):\n",
    "\n",
    "        all_hist = []\n",
    "        for varlen_x, seqlen_x in zip(varlen_list, seqlen_list):\n",
    "\n",
    "            max_len, emb_dim = varlen_x.shape[1], varlen_x.shape[2]\n",
    "            mask = self._sequence_mask(seqlen_x, max_len, emb_dim)\n",
    "\n",
    "            if self.method == 'max':\n",
    "                hist = varlen_x - (1 - mask) * self.eps\n",
    "                hist = torch.max(hist, dim=1)[0]\n",
    "\n",
    "                return hist\n",
    "\n",
    "            hist = mask * varlen_x\n",
    "            hist = torch.sum(hist, dim=1, keepdim=False)\n",
    "\n",
    "            if self.method == 'mean':\n",
    "                hist = torch.div(hist, seqlen_x.type(torch.float32) + self.eps)\n",
    "            all_hist.append(hist)\n",
    "\n",
    "        return all_hist\n",
    "\n",
    "    def _sequence_mask(self, seqlen_x, max_len, emb_dim):\n",
    "\n",
    "        rowvec = torch.arange(0, max_len).to(seqlen_x.device)\n",
    "        mask = (seqlen_x > rowvec)  # (B, max_len)\n",
    "        mask = mask.unsqueeze(dim=2)  # (B, max_len, 1)\n",
    "        mask = torch.repeat_interleave(mask, emb_dim, dim=2)  # (B, max_len, E)\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FM(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(FM, self).__init__()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        fm_input = inputs\n",
    "\n",
    "        square_of_sum = torch.pow(torch.sum(fm_input, dim=1, keepdim=True), 2)\n",
    "        sum_of_square = torch.sum(fm_input * fm_input, dim=1, keepdim=True)\n",
    "        cross_term = square_of_sum - sum_of_square\n",
    "        cross_term = 0.5 * torch.sum(cross_term, dim=2, keepdim=False)\n",
    "\n",
    "        return cross_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepFM(nn.Module):\n",
    "\n",
    "    def __init__(self, SparseFeatInfoList, VarLenSparseFeatInfoList, DenseFeatInfoList, device='cpu'):\n",
    "        super(DeepFM, self).__init__()\n",
    "\n",
    "        self.SparseFeatInfoList = SparseFeatInfoList\n",
    "        self.VarLenSparseFeatInfoList = VarLenSparseFeatInfoList\n",
    "        self.DenseFeatInfoList = DenseFeatInfoList\n",
    "\n",
    "        self.sparse_dim, self.varlen_dim, self.dense_dim = self._return_dim()\n",
    "\n",
    "        # embedding layer\n",
    "        self.embedding_layer = EmbeddingLayer(SparseFeatInfoList, VarLenSparseFeatInfoList, device=device)\n",
    "        self.sequence_pooling_layer = SequencePoolingLayer(device=device)\n",
    "\n",
    "        # Linear Model\n",
    "        linear_input_dim = self.sparse_dim\n",
    "        self.linear_model = nn.Sequential(\n",
    "            nn.Linear(linear_input_dim, 1))\n",
    "\n",
    "        # FM\n",
    "        self.fm = FM()\n",
    "\n",
    "        # DNN for Sparse and Varlen\n",
    "        dnn_input_dim1 = self.sparse_dim + self.varlen_dim\n",
    "        self.dnn1 = nn.Sequential(\n",
    "            nn.Linear(dnn_input_dim1, 512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # DNN for Dense\n",
    "        dnn_input_dim2 = self.dense_dim\n",
    "        self.dnn2 = nn.Sequential(\n",
    "            nn.Linear(dnn_input_dim2, 256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # DNN\n",
    "        dnn_input_dim3 = 256 + 512\n",
    "        self.dnn3 = nn.Sequential(\n",
    "            nn.Linear(dnn_input_dim3, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "        )\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Linear, nn.Conv2d)):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "        self.to(device)\n",
    "\n",
    "    def _return_dim(self):\n",
    "\n",
    "        sparse_dim, varlen_dim, dense_dim = 0, 0, 0\n",
    "        for v in self.SparseFeatInfoList:\n",
    "            sparse_dim += v.emb_dim\n",
    "\n",
    "        for v in self.VarLenSparseFeatInfoList:\n",
    "            varlen_dim += v.emb_dim\n",
    "\n",
    "        for v in self.DenseFeatInfoList:\n",
    "            dense_dim += v.emb_dim\n",
    "\n",
    "        return sparse_dim, varlen_dim, dense_dim\n",
    "\n",
    "    def _dict2list(self, feats):\n",
    "\n",
    "        all_feats = []\n",
    "\n",
    "        for feat in feats.values():\n",
    "            if len(feat.shape) == 1:\n",
    "                feat = feat.unsqueeze(dim=1)\n",
    "            all_feats += [feat]\n",
    "\n",
    "        return all_feats\n",
    "\n",
    "    def forward(self, sparseX, varlenX, denseX):\n",
    "\n",
    "        # pdb.set_trace()\n",
    "        sparseX_emb, varlenX_emb = self.embedding_layer(sparseX, varlenX)\n",
    "        seq_length = self.embedding_layer.get_seq_len(varlenX)\n",
    "\n",
    "        # 单独找出来 userid\n",
    "        sparseX_userid_emb = sparseX_emb.pop('userid')\n",
    "        sparseX_userid_list = list(torch.chunk(sparseX_userid_emb, 4, dim=1))\n",
    "        \n",
    "        sparseX_list = self._dict2list(sparseX_emb)\n",
    "        varlenX_list = self._dict2list(varlenX_emb)\n",
    "        denseX_list = self._dict2list(denseX)\n",
    "        seq_length_list = self._dict2list(seq_length)\n",
    "        \n",
    "        # sparseX_list = [x.squeeze() for x in sparseX_list]\n",
    "        hist_list = self.sequence_pooling_layer(varlenX_list, seq_length_list)\n",
    "        sparseX_input = torch.stack(sparseX_list + sparseX_userid_list, dim=1)\n",
    "        hist_input = torch.stack(hist_list, dim=1)\n",
    "\n",
    "        linear_input = torch.cat(sparseX_list + [sparseX_userid_emb], dim=1)\n",
    "        fm_input = torch.cat([sparseX_input], dim=1)\n",
    "        nn1_input = torch.cat(sparseX_list + hist_list + [sparseX_userid_emb], dim=1)\n",
    "        nn2_input = torch.cat(denseX_list, dim=1)\n",
    "\n",
    "        # note that\n",
    "        logit = self.linear_model(linear_input)\n",
    "        logit += self.fm(fm_input)\n",
    "\n",
    "        nn1_output = self.dnn1(nn1_input)\n",
    "        nn2_output = self.dnn2(nn2_input)\n",
    "\n",
    "        nn3_input = torch.cat([nn1_output, nn2_output], dim=1)\n",
    "        logit += self.dnn3(nn3_input)\n",
    "\n",
    "        return logit\n",
    "\n",
    "    def loss_func(self, logit, label, pos_weight):\n",
    "\n",
    "        logit = logit.squeeze()\n",
    "        loss = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(pos_weight))\n",
    "\n",
    "        return loss(logit, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseFeatInfo(object):\n",
    "\n",
    "    def __init__(self, name, vocabulary_size, emb_dim):\n",
    "        self.name = name\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "        self.emb_dim = emb_dim\n",
    "\n",
    "\n",
    "class DenseFeatInfo(object):\n",
    "\n",
    "    def __init__(self, name, emb_dim):\n",
    "        self.name = name\n",
    "        self.emb_dim = emb_dim\n",
    "\n",
    "\n",
    "class VarLenSparseFeatInfo(object):\n",
    "\n",
    "    def __init__(self, name, max_len, vocabulary_size, emb_dim):\n",
    "        self.name = name\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "        self.emb_dim = emb_dim\n",
    "        self.max_len = max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def early_stopping(evaluates, inval=2):\n",
    "    if len(evaluates) <= inval:\n",
    "        return False\n",
    "    else:\n",
    "        for i in range(len(evaluates) - inval - 1, len(evaluates) - 1):\n",
    "            if evaluates[i] < evaluates[i + 1]:\n",
    "                return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# 评估函数加速版\n",
    "def filter_userid(df, label_name):\n",
    "    def func(x):\n",
    "\n",
    "        mask = (x[label_name] == 1).mean()\n",
    "        if mask == 0.0 or mask == 1.0:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "    new_df = df.groupby('userid')[['userid'] + [label_name]]\n",
    "    filter_u = new_df.apply(func)\n",
    "\n",
    "    eliminate_u = filter_u[filter_u == False]\n",
    "\n",
    "    return eliminate_u.index\n",
    "\n",
    "\n",
    "\n",
    "def uAUC(preds, labels, eliminate_array, userid_array):\n",
    "\n",
    "    isin_mask = ~np.isin(userid_array, eliminate_array)\n",
    "\n",
    "    userid_array = userid_array[isin_mask]\n",
    "    preds = preds[isin_mask]\n",
    "    labels = labels[isin_mask]\n",
    "\n",
    "    # 算法\n",
    "    res = np.column_stack((userid_array, preds, labels))\n",
    "    res = res[res[:, 0].argsort()] # 按 userid 排序 \n",
    "\n",
    "    u_res_list = np.split(res[:,1:3], np.unique(res[:, 0], return_index=True)[1][1:]) # 类似于 groupby\n",
    "\n",
    "    all_auc = 0.0\n",
    "    for u_res in u_res_list:\n",
    "        pre, lab = u_res[:, 0], u_res[:, 1]\n",
    "        all_auc += roc_auc_score(lab, pre)\n",
    "\n",
    "    return all_auc / len(u_res_list)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def uAUC(labels, preds, user_id_list):\n",
    "    user_pred = defaultdict(lambda: [])\n",
    "    user_truth = defaultdict(lambda: [])\n",
    "\n",
    "    for idx, truth in enumerate(labels):\n",
    "        user_id = user_id_list[idx]\n",
    "        pred = preds[idx]\n",
    "        truth = labels[idx]\n",
    "        user_pred[user_id].append(pred)\n",
    "        user_truth[user_id].append(truth)\n",
    "\n",
    "    user_flag = defaultdict(lambda: False)\n",
    "    for user_id in set(user_id_list):\n",
    "        truths = user_truth[user_id]\n",
    "        flag = False\n",
    "\n",
    "        # 若全是正样本或全是负样本，则flag为False\n",
    "        for i in range(len(truths) - 1):\n",
    "            if truths[i] != truths[i + 1]:\n",
    "                flag = True\n",
    "                break\n",
    "\n",
    "        user_flag[user_id] = flag\n",
    "\n",
    "    total_auc = 0.0\n",
    "    size = 0.0\n",
    "    for user_id in user_flag:\n",
    "        if user_flag[user_id]:\n",
    "            auc = roc_auc_score(np.asarray(user_truth[user_id]), np.asarray(user_pred[user_id]))\n",
    "            total_auc += auc\n",
    "            size += 1.0\n",
    "\n",
    "    user_auc = float(total_auc) / size\n",
    "    return user_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Session(object):\n",
    "    \n",
    "    \n",
    "    def __init__(self, model, device='cpu'):\n",
    "        \n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        \n",
    "    def to_device(self, x):\n",
    "        \n",
    "        if isinstance(x, dict):\n",
    "            for key in x.keys():\n",
    "                x[key] = x[key].to(self.device)\n",
    "        else:\n",
    "            x = x.to(self.device)\n",
    "        return x\n",
    "        \n",
    "    def train(self, loader, optimizer, pos_weight):\n",
    "        \n",
    "        all_loss = 0.0\n",
    "        self.model.train()\n",
    "        \n",
    "        with tqdm(loader) as tqdm_loader:\n",
    "            for d in tqdm_loader:\n",
    "                #pdb.set_trace()\n",
    "                sparseX = self.to_device(d[0])\n",
    "                varlenX = self.to_device(d[1])\n",
    "                denseX = self.to_device(d[2])\n",
    "                label = self.to_device(d[3])\n",
    "\n",
    "                logit = self.model(sparseX, varlenX, denseX)\n",
    "                loss = self.model.loss_func(logit, label, pos_weight)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                all_loss += loss.item()\n",
    "        \n",
    "        return all_loss / len(loader)\n",
    "    \n",
    "    \n",
    "    def valid(self, loader):\n",
    "        \n",
    "        self.model.eval()\n",
    "        \n",
    "        all_predict, all_label, all_userid = [], [], []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for d in loader:\n",
    "                \n",
    "                sparseX = self.to_device(d[0])\n",
    "                varlenX = self.to_device(d[1])\n",
    "                denseX = self.to_device(d[2])\n",
    "                label = self.to_device(d[3])\n",
    "                \n",
    "                userid_array = sparseX['userid'].detach().cpu().numpy()\n",
    "                label = label.detach().cpu().numpy()\n",
    "                \n",
    "                logit = self.model(sparseX, varlenX, denseX).squeeze()\n",
    "                logit = torch.sigmoid(logit).detach().cpu().numpy()\n",
    "                \n",
    "                all_userid.append(userid_array)\n",
    "                all_predict.append(logit)\n",
    "                all_label.append(label)\n",
    "                \n",
    "        #uauc = uAUC(np.concatenate(all_predict, axis=0),\n",
    "        #            np.concatenate(all_label, axis=0),\n",
    "        #            eliminate_u,\n",
    "        #            np.concatenate(all_userid, axis=0))\n",
    "        \n",
    "        uauc = uAUC(np.concatenate(all_label, axis=0),\n",
    "                    np.concatenate(all_predict, axis=0),\n",
    "                    np.concatenate(all_userid, axis=0))\n",
    "                \n",
    "        return uauc\n",
    "    \n",
    "    \n",
    "    def predict(self, loader):\n",
    "        \n",
    "        self.model.eval()\n",
    "        \n",
    "        all_pred = []\n",
    "        with torch.no_grad():\n",
    "            for d in loader:\n",
    "                sparseX = self.to_device(d[0])\n",
    "                varlenX = self.to_device(d[1])\n",
    "                denseX = self.to_device(d[2])\n",
    "                \n",
    "                logit = self.model(sparseX, varlenX, denseX).squeeze()\n",
    "                logit = torch.sigmoid(logit).detach().cpu().numpy()\n",
    "                \n",
    "                all_pred.append(logit)\n",
    "                \n",
    "        return np.concatenate(all_pred, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    # Args\n",
    "    root_path = '/zhaochen/wechat_comp'\n",
    "    device = 'cuda:0'\n",
    "    \n",
    "    validate = True\n",
    "    lr = 0.01\n",
    "    l2_decay = 1e-5\n",
    "    num_workers = 8\n",
    "    \n",
    "    num_epochs = [10, 10, 10, 10, 10, 10, 10]\n",
    "    batch_size = [1024 * 16, 1024 * 10, 1024 * 10, 1024 * 10, 1024 * 10, 1024 * 10, 1024 * 10]\n",
    "    pos_weight = [3.0000, 2.0000, 5.0000, 5.0000, 7.0000, 8.0000, 7.0000]\n",
    "    \n",
    "    # load basic\n",
    "    user_action = pd.read_csv(root_path + '/data/preprocess/user_action.csv')\n",
    "    feed_info = pd.read_csv(root_path + '/data/preprocess/feed_info.csv')\n",
    "    test_a = pd.read_csv(root_path + '/data/preprocess/test_a.csv')\n",
    "    \n",
    "    # statistical information\n",
    "    device_voc = max(test_a['device'].unique().max(), user_action['device'].unique().max())\n",
    "    with open(root_path+'/data/preprocess/statistical.pkl', 'rb') as f:\n",
    "        userid_voc, feedid_voc, authorid_voc, bgm_song_id_voc, bgm_singer_id_voc = pickle.load(f)\n",
    "    \n",
    "    # feature engineer\n",
    "    # feed_history = np.load(root_path + 'feed_history_w2v_13_mean.npy')\n",
    "    feed_embeddings = np.load(root_path+'/data/process/feed_embeddings_512.npy')\n",
    "    \n",
    "    USE_ACT_FEAT = [\n",
    "\n",
    "        # basic feat\n",
    "        'userid',        \n",
    "        'feedid',       \n",
    "        'device',\n",
    "        'date_',\n",
    "\n",
    "        # label\n",
    "        'read_comment',\n",
    "        'comment',\n",
    "        'like',\n",
    "        'click_avatar',\n",
    "        'forward',\n",
    "        'follow',\n",
    "        'favorite']\n",
    "    \n",
    "    USE_FEED_FEAT = [\n",
    "        'feedid',\n",
    "        'authorid',\n",
    "        'bgm_song_id',\n",
    "        'bgm_singer_id',\n",
    "        'manual_keyword_list',\n",
    "        'manual_tag_list',\n",
    "        'videoplayseconds', \n",
    "    ]\n",
    "    \n",
    "    user_action = user_action[USE_ACT_FEAT]\n",
    "    feed_info = feed_info[USE_FEED_FEAT]\n",
    "    \n",
    "    feed_info = feed_info.sort_values(by='feedid')\n",
    "    \n",
    "    feed_info['videoplayseconds'] = process_videoplayseconds(feed_info)\n",
    "    tags, tags_max_len, tags_voc = process_varlensparse(feed_info, 'manual_tag_list')\n",
    "    keywords, keywords_max_len, keywords_voc = process_varlensparse(feed_info, 'manual_keyword_list')\n",
    "    \n",
    "    videoplayseconds_discrete, videoplayseconds_discrete_voc = videoplayseconds_discrete_process(feed_info)\n",
    "    \n",
    "    if validate:\n",
    "        train_user_action, test_user_action = split_data_to_train_validation(user_action)  \n",
    "    else:\n",
    "        train_user_action = user_action\n",
    "        test_a['date_'] = user_action['date_'].max() + 1\n",
    "        test_user_action = test_a\n",
    "        \n",
    "    train_inputs_feat = {\n",
    "\n",
    "        'userid': train_user_action['userid'].to_numpy(np.long),\n",
    "        'feedid': train_user_action['feedid'].to_numpy(np.long),\n",
    "        'device': train_user_action['device'].to_numpy(np.long),\n",
    "\n",
    "        'authorid': padding(feed_info['authorid'].to_numpy(np.long)),\n",
    "        'bgm_song_id': padding(feed_info['bgm_song_id'].to_numpy(np.long)),\n",
    "        'bgm_singer_id': padding(feed_info['bgm_singer_id'].to_numpy(np.long)),\n",
    "\n",
    "        'feed_embeddings': feed_embeddings.astype(np.float32),\n",
    "        'tags': tags.astype(np.long),\n",
    "        'keywords': keywords.astype(np.long),\n",
    "        'videoplayseconds_discrete' : padding(videoplayseconds_discrete),\n",
    "\n",
    "        # 'feed_history': feed_history,\n",
    "    }\n",
    "\n",
    "    train_inputs_label = {\n",
    "        'read_comment' : train_user_action['read_comment'].to_numpy(np.float32),\n",
    "        'like' : train_user_action['like'].to_numpy(np.float32),\n",
    "        'click_avatar' : train_user_action['click_avatar'].to_numpy(np.float32),\n",
    "        'forward' : train_user_action['forward'].to_numpy(np.float32),\n",
    "        'follow' : train_user_action['follow'].to_numpy(np.float32),\n",
    "        'favorite': train_user_action['favorite'].to_numpy(np.float32),\n",
    "        'comment': train_user_action['comment'].to_numpy(np.float32),\n",
    "    }\n",
    "    \n",
    "    test_inputs_feat = {\n",
    "\n",
    "        'userid': test_user_action['userid'].to_numpy(np.long),\n",
    "        'feedid': test_user_action['feedid'].to_numpy(np.long),\n",
    "        'device': test_user_action['device'].to_numpy(np.long),\n",
    "        'authorid': padding(feed_info['authorid'].to_numpy(np.long)),\n",
    "        'bgm_song_id': padding(feed_info['bgm_song_id'].to_numpy(np.long)),\n",
    "        'bgm_singer_id': padding(feed_info['bgm_singer_id'].to_numpy(np.long)),\n",
    "\n",
    "        'feed_embeddings': feed_embeddings.astype(np.float32),\n",
    "        'tags': tags.astype(np.long),\n",
    "        'keywords': keywords.astype(np.long),\n",
    "        'videoplayseconds_discrete' : padding(videoplayseconds_discrete),\n",
    "        # 'feed_history': feed_history,\n",
    "    }\n",
    "\n",
    "    test_inputs_label = {\n",
    "        'read_comment' : test_user_action['read_comment'].to_numpy(np.float32),\n",
    "        'like' : test_user_action['like'].to_numpy(np.float32),\n",
    "        'click_avatar' : test_user_action['click_avatar'].to_numpy(np.float32),\n",
    "        'forward' : test_user_action['forward'].to_numpy(np.float32),\n",
    "        'follow' : test_user_action['follow'].to_numpy(np.float32),\n",
    "        'favorite': test_user_action['favorite'].to_numpy(np.float32),\n",
    "        'comment': test_user_action['comment'].to_numpy(np.float32),\n",
    "    }\n",
    "    \n",
    "    \n",
    "    SparseFeatInfoList = [\n",
    "        SparseFeatInfo('userid', userid_voc, 512),\n",
    "        SparseFeatInfo('feedid', feedid_voc+1, 128),\n",
    "        SparseFeatInfo('device', device_voc+1,  128),\n",
    "        SparseFeatInfo('authorid', authorid_voc+1, 128),\n",
    "        SparseFeatInfo('bgm_song_id', bgm_song_id_voc+1, 128),\n",
    "        SparseFeatInfo('bgm_singer_id', bgm_singer_id_voc+1, 128),\n",
    "        SparseFeatInfo('videoplayseconds_discrete', videoplayseconds_discrete_voc+1, 128),\n",
    "    ]\n",
    "\n",
    "    VarLenSparseFeatInfoList = [\n",
    "        VarLenSparseFeatInfo('keywords', keywords_max_len, keywords_voc+1, 128),\n",
    "        VarLenSparseFeatInfo('tags', tags_max_len, tags_voc+1, 128),\n",
    "    ]\n",
    "\n",
    "    DenseFeatInfoList = [\n",
    "        DenseFeatInfo('feed_embeddings', 512),\n",
    "        # DenseFeatInfo('feed_history', 128),\n",
    "    ]\n",
    "\n",
    "    labels = {\n",
    "        'read_comment': 4,\n",
    "        'like': 3,\n",
    "        'click_avatar': 2,\n",
    "        'forward': 1,\n",
    "        'favorite': 1,\n",
    "        'comment': 1,\n",
    "        'follow': 1,\n",
    "    }\n",
    "    \n",
    "    \n",
    "    result = {}\n",
    "    with open(root_path + '/log/result_' + time.strftime('%Y-%m-%d-%m-%s', time.localtime()) + '.txt', 'w+') as f:\n",
    "        for i, (label_name, label_weight) in enumerate(labels.items()):\n",
    "            train_tensordata = TrainTensorData(train_inputs_feat, train_inputs_label, label_name)\n",
    "            train_loader = DataLoader(train_tensordata, batch_size=batch_size[i], shuffle=True, num_workers=num_workers)\n",
    "            \n",
    "            test_tensordata = TrainTensorData(test_inputs_feat, test_inputs_label, label_name)\n",
    "            test_loader = DataLoader(test_tensordata, batch_size=1024*32, shuffle=False, num_workers=num_workers)\n",
    "            \n",
    "            deepfm = DeepFM(SparseFeatInfoList, VarLenSparseFeatInfoList, DenseFeatInfoList, device=device)\n",
    "            optimizer = optim.Adagrad(filter(lambda p: p.requires_grad, deepfm.parameters()), lr=lr, weight_decay=l2_decay)\n",
    "            \n",
    "            sess = Session(deepfm, device)\n",
    "            \n",
    "            best_epoch = 0\n",
    "            best_uauc = 0\n",
    "            uauc_list = []\n",
    "            for j in range(num_epochs[i]):\n",
    "                try:\n",
    "                    loss = sess.train(train_loader, optimizer, pos_weight[i])\n",
    "                    print(\"epoch: {:d}, loss:{:.6f}\".format(j + 1, loss))\n",
    "                    print(\"epoch: {:d}, loss:{:.6f}\".format(j + 1, loss), file=f)\n",
    "                    \n",
    "                    uauc = sess.valid(test_loader)\n",
    "                    print(label_name + \" auc:{:.6f}\".format(uauc))\n",
    "                    print(label_name + \" auc:{:.6f}\".format(uauc), file=f)\n",
    "                    \n",
    "                    if best_uauc < uauc:\n",
    "                        best_epoch = j + 1\n",
    "                        best_uauc = uauc\n",
    "                        \n",
    "                    uauc_list.append(uauc)\n",
    "                    # torch.save(deepfm.state_dict(), './parameters/valid_' + label_name + str(j+1) + '.pth')\n",
    "                    \n",
    "                    if early_stopping(uauc_list, 2):\n",
    "                        print('earlystoping !')\n",
    "                        print('earlystoping !', file=f)\n",
    "                        break\n",
    "                except KeyboardInterrupt:\n",
    "                    break\n",
    "                    \n",
    "            result[label_name] = best_uauc\n",
    "            print(label_name + \" best uauc: ({:d}):{:.6f}\".format(best_epoch, best_uauc))\n",
    "            print(label_name + \" best uauc: ({:d}):{:.6f}\".format(best_epoch, best_uauc), file=f)\n",
    "        \n",
    "        total_uauc = 0.0\n",
    "        all_weight = 0.0\n",
    "\n",
    "        for u in result.keys():\n",
    "            total_uauc += result[u] * labels[u]\n",
    "            all_weight += labels[u] * 1.0\n",
    "\n",
    "        print(\"the final result:{:.6f}\".format(total_uauc / all_weight))\n",
    "        print(\"the final result:{:.6f}\".format(total_uauc / all_weight), file=f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
